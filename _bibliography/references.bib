
---
---
@article{saxe_pathway_2022,
	title = {The {Pathway} {Race} {Reduction}: {Dynamics} of {Abstraction} in {Gated} {Networks}},
	journal = {International Conference on Machine Learning},
	author = {Saxe, A.M. and Sodhani, S. and Lewallen, S.},
	year = {2022},
}

@article{lee_maslows_2022,
	title = {Maslow's {Hammer} for {Catastrophic} {Forgetting}: {Node} {Re}-{Use} vs {Node} {Activation}},
	journal = {ICML},
	author = {Lee, S. and Mannelli, S.S. and Clopath, C. and Goldt, S. and Saxe, A.M.},
	year = {2022},
}

@article{flesch_orthogonal_2022,
	title = {Orthogonal representations for robust context-dependent task performance in brains and neural networks},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00005-8},
	doi = {10.1016/j.neuron.2022.01.005},
	language = {English},
	number = {110},
	urldate = {2022-01-26},
	journal = {Neuron},
	author = {Flesch, Timo and Juechems, K. and Dumbalska, T. and Saxe*, A. and Summerfield*, Christopher},
	month = jan,
	year = {2022},
	note = {Publisher: Elsevier},
	keywords = {artificial neural networks, functional magnetic resonance imaging, orthogonal manifolds, representational geometry, task learning},
	pages = {*Equal contributions.},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/62LWFB9Y/Flesch et al. - 2022 - Orthogonal representations for robust context-depe.pdf:application/pdf;Snapshot:/Users/asaxe/Zotero/storage/45UHRZYH/S0896-6273(22)00005-8.html:text/html},
}

@inproceedings{lee_continual_2021,
	title = {Continual {Learning} in the {Teacher}-{Student} {Setup}: {Impact} of {Task} {Similarity}},
	shorttitle = {Continual {Learning} in the {Teacher}-{Student} {Setup}},
	url = {https://proceedings.mlr.press/v139/lee21e.html},
	abstract = {Continual learning\{—\}the ability to learn many tasks in sequence\{—\}is critical for artificial learning systems. Yet standard training methods for deep networks often suffer from catastrophic forgetting, where learning new tasks erases knowledge of the earlier tasks. While catastrophic forgetting labels the problem, the theoretical reasons for interference between tasks remain unclear. Here, we attempt to narrow this gap between theory and practice by studying continual learning in the teacher-student setup. We extend previous analytical work on two-layer networks in the teacher-student setup to multiple teachers. Using each teacher to represent a different task, we investigate how the relationship between teachers affects the amount of forgetting and transfer exhibited by the student when the task switches. In line with recent work, we find that when tasks depend on similar features, intermediate task similarity leads to greatest forgetting. However, feature similarity is only one way in which tasks may be related. The teacher-student approach allows us to disentangle task similarity at the level of {\textbackslash}emph\{readouts\} (hidden-to-output weights) as well as {\textbackslash}emph\{features\} (input-to-hidden weights). We find a complex interplay between both types of similarity, initial transfer/forgetting rates, maximum transfer/forgetting, and the long-time (post-switch) amount of transfer/forgetting. Together, these results help illuminate the diverse factors contributing to catastrophic forgetting.},
	urldate = {2021-12-10},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	author = {Lee, S. and Goldt, S. and Saxe, A.},
	year = {2021},
	keywords = {publications},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/A6ZULECW/Lee et al. - 2021 - Continual Learning in the Teacher-Student Setup I.pdf:application/pdf;Supplementary PDF:/Users/asaxe/Zotero/storage/Y59X6SVQ/Lee et al. - 2021 - Continual Learning in the Teacher-Student Setup I.pdf:application/pdf},
}


@article{saglietti_analytical_2021,
	title = {An {Analytical} {Theory} of {Curriculum} {Learning} in {Teacher}-{Student} {Networks}},
	url = {http://arxiv.org/abs/2106.08068},
	abstract = {In humans and animals, curriculum learning -- presenting data in a curated order - is critical to rapid learning and effective pedagogy. Yet in machine learning, curricula are not widely used and empirically often yield only moderate benefits. This stark difference in the importance of curriculum raises a fundamental theoretical question: when and why does curriculum learning help? In this work, we analyse a prototypical neural network model of curriculum learning in the high-dimensional limit, employing statistical physics methods. Curricula could in principle change both the learning speed and asymptotic performance of a model. To study the former, we provide an exact description of the online learning setting, confirming the long-standing experimental observation that curricula can modestly speed up learning. To study the latter, we derive performance in a batch learning setting, in which a network trains to convergence in successive phases of learning on dataset slices of varying difficulty. With standard training losses, curriculum does not provide generalisation benefit, in line with empirical observations. However, we show that by connecting different learning phases through simple Gaussian priors, curriculum can yield a large improvement in test performance. Taken together, our reduced analytical descriptions help reconcile apparently conflicting empirical results and trace regimes where curriculum learning yields the largest gains. More broadly, our results suggest that fully exploiting a curriculum may require explicit changes to the loss function at curriculum boundaries.},
	urldate = {2021-12-10},
	journal = {arXiv:2106.08068 [cond-mat, stat]},
	author = {Saglietti, L. and Mannelli, S.S. and Saxe, A.},
	year = {2021},
	keywords = {arxiv},
	file = {arXiv Fulltext PDF:/Users/asaxe/Zotero/storage/VIFGZAE5/Saglietti et al. - 2021 - An Analytical Theory of Curriculum Learning in Tea.pdf:application/pdf;arXiv.org Snapshot:/Users/asaxe/Zotero/storage/3KYWXJJB/2106.html:text/html},
}

@article{gerace_probing_2021,
	title = {Probing transfer learning with a model of synthetic correlated datasets},
	url = {http://arxiv.org/abs/2106.05418},
	abstract = {Transfer learning can significantly improve the sample efficiency of neural networks, by exploiting the relatedness between a data-scarce target task and a data-abundant source task. Despite years of successful applications, transfer learning practice often relies on ad-hoc solutions, while theoretical understanding of these procedures is still limited. In the present work, we re-think a solvable model of synthetic data as a framework for modeling correlation between data-sets. This setup allows for an analytic characterization of the generalization performance obtained when transferring the learned feature map from the source to the target task. Focusing on the problem of training two-layer networks in a binary classification setting, we show that our model can capture a range of salient features of transfer learning with real data. Moreover, by exploiting parametric control over the correlation between the two data-sets, we systematically investigate under which conditions the transfer of features is beneficial for generalization.},
	urldate = {2021-12-10},
	journal = {arXiv:2106.05418 [cond-mat]},
	author = {Gerace, F. and Saglietti, L. and Mannelli, S.S. and Saxe, A. and Zdeborová, L.},
	year = {2021},
	keywords = {arxiv},
	file = {arXiv Fulltext PDF:/Users/asaxe/Zotero/storage/QVL24DPA/Gerace et al. - 2021 - Probing transfer learning with a model of syntheti.pdf:application/pdf;arXiv.org Snapshot:/Users/asaxe/Zotero/storage/7A5S4EHC/2106.html:text/html},
}

@article{nelli_neural_2021,
	title = {Neural knowledge assembly in humans and deep networks},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.21.465374v2},
	abstract = {Human understanding of the world can change rapidly when new information comes to light, such as when a plot twist occurs in a work of fiction. This flexible “knowledge assembly” requires few-shot reorganisation of neural codes for relations among objects and events. However, existing computational theories are largely silent about how this could occur. Here, participants learned a transitive ordering among novel objects within two distinct contexts, before exposure to new knowledge that revealed how they were linked. BOLD signals in dorsal frontoparietal cortical areas revealed that objects were rapidly and dramatically rearranged on the neural manifold after minimal exposure to linking information. We then adapt stochastic online gradient descent to permit similar rapid knowledge assembly in a neural network model.},
	language = {en},
	urldate = {2021-12-10},
	journal = {bioRxiv},
	author = {Nelli, S. and Braun, L. and Dumbalska, T. and Saxe, A. and Summerfield, C.},
	year = {2021},
	keywords = {arxiv},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/5S68PZ3V/Nelli et al. - 2021 - Neural knowledge assembly in humans and deep netwo.pdf:application/pdf;Snapshot:/Users/asaxe/Zotero/storage/3S8AUUPX/2021.10.21.465374v2.html:text/html},
}

@article{sun_organizing_2021,
	title = {Organizing memories for generalization in complementary learning systems},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.13.463791v1},
	abstract = {Our ability to remember the past is essential for guiding our future behavior. Psychological and neurobiological features of declarative memories are known to transform over time in a process known as systems consolidation. While many theories have sought to explain the time-varying role of hippocampal and neocortical brain areas, the computational principles that govern these transformations remain unclear. Here we propose a theory of systems consolidation in which hippocampal-cortical interactions serve to optimize generalizations that guide future adaptive behavior. We use mathematical analysis of neural network models to characterize fundamental performance tradeoffs in systems consolidation, revealing that memory components should be organized according to their predictability. The theory shows that multiple interacting memory systems can outperform just one, normatively unifying diverse experimental observations and making novel experimental predictions. Our results suggest that the psychological taxonomy and neurobiological organization of declarative memories reflect a system optimized for behaving well in an uncertain future.},
	urldate = {2021-12-10},
	journal = {bioRxiv},
	author = {Sun, W. and Advani, M. and Spruston, N. and Saxe*, A. and Fitzgerald*, J.E.},
	year = {2021},
	keywords = {arxiv},
	pages = {*Equal contribution},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/4KGS4EZL/Sun et al. - 2021 - Organizing memories for generalization in compleme.pdf:application/pdf;Snapshot:/Users/asaxe/Zotero/storage/RQ7D33EY/2021.10.13.463791v1.html:text/html},
}

@article{juechems_inferring_2021,
	title = {Inferring {Actions}, {Intentions}, and {Causal} {Relations} in a {Deep} {Neural} {Network}},
	volume = {43},
	url = {https://escholarship.org/uc/item/2mp5t991},
	abstract = {From a young age, we can select actions to achieve desired goals, infer the goals of other agents, and learn causal relations in our environment through social interactions. Crucially, these abilities are productive and generative: we can impute desires to others that we have never held ourselves. These abilities are often captured by only partially overlapping models, each requiring substantial changes to fit combinations of abilities. Here, in an attempt to unify previous models, we present a neural network underpinned by the linearly solvable Markov Decision Process (LMDP) framework which permits a distributed representation of tasks. The network contains two pathways: one captures the desirability of states, and another encodes the passive dynamics of state transitions in the absence of control. Interactions between pathways are bound by a principle of rational action, enabling generative inference of actions, goals, and causal relations supported by gradient updates to parts of the network.},
	language = {en},
	urldate = {2021-12-10},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Juechems, K. and Saxe, A.},
	year = {2021},
	keywords = {publications},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/WD2HMEH6/Juechems and Saxe - 2021 - Inferring Actions, Intentions, and Causal Relation.pdf:application/pdf;Snapshot:/Users/asaxe/Zotero/storage/V57SZDYT/2mp5t991.html:text/html},
}

@article{saxe_if_2021,
	title = {If deep learning is the answer, what is the question?},
	volume = {22},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-020-00395-8},
	doi = {10.1038/s41583-020-00395-8},
	abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
	language = {en},
	number = {1},
	urldate = {2021-09-06},
	journal = {Nature Reviews Neuroscience},
	author = {Saxe, A. and Nelli, S. and Summerfield, C.},
	year = {2021},
	keywords = {publications},
	pages = {55--67},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/BZXBBND2/Saxe et al. - 2021 - If deep learning is the answer, what is the questi.pdf:application/pdf;Snapshot:/Users/asaxe/Zotero/storage/JQ9VW3Z8/s41583-020-00395-8.html:text/html},
}

@article{goldt_dynamics_2020,
	title = {Dynamics of stochastic gradient descent for two-layer neural networks in the teacher–student setup},
	volume = {2020},
	issn = {1742-5468},
	url = {https://doi.org/10.1088/1742-5468/abc61e},
	doi = {10.1088/1742-5468/abc61e},
	abstract = {Deep neural networks achieve stellar generalisation even when they have enough parameters to easily fit all their training data. We study this phenomenon by analysing the dynamics and the performance of over-parameterised two-layer neural networks in the teacher–student setup, where one network, the student, is trained on data generated by another network, called the teacher. We show how the dynamics of stochastic gradient descent (SGD) is captured by a set of differential equations and prove that this description is asymptotically exact in the limit of large inputs. Using this framework, we calculate the final generalisation error of student networks that have more parameters than their teachers. We find that the final generalisation error of the student increases with network size when training only the first layer, but stays constant or even decreases with size when training both layers. We show that these different behaviours have their root in the different solutions SGD finds for different activation functions. Our results indicate that achieving good generalisation in neural networks goes beyond the properties of SGD alone and depends on the interplay of at least the algorithm, the model architecture, and the data set.},
	language = {en},
	number = {12},
	urldate = {2021-12-10},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Goldt, S. and Advani, M.S. and Saxe, A.M. and Krzakala, F. and Zdeborová, L.},
	year = {2020},
	note = {Publisher: IOP Publishing},
	keywords = {publications},
	pages = {124010},
	file = {IOP Full Text PDF:/Users/asaxe/Zotero/storage/DMZ24H67/Goldt et al. - 2020 - Dynamics of stochastic gradient descent for two-la.pdf:application/pdf},
}

@techreport{musslick_rational_2020,
	title = {On the {Rational} {Boundedness} of {Cognitive} {Control}: {Shared} {Versus} {Separated} {Representations}},
	shorttitle = {On the {Rational} {Boundedness} of {Cognitive} {Control}},
	url = {https://psyarxiv.com/jkhdf/},
	abstract = {One of the most fundamental and striking limitations of human cognition appears to be a constraint in the number of control-dependent processes that can be executed at one time. This constraint motivates one of the most influential tenets of cognitive psychology: that cognitive control relies on a central, limited capacity processing mechanism that imposes a seriality constraint on processing. Here we provide a formally explicit challenge to this view. We argue that the causality is reversed: the constraints on control-dependent behavior reflect a rational bound that control mechanisms impose on processing, to prevent processing interference that arises if two or more tasks engage the same resource to be executed. We use both mathematical and numerical analyses of shared representations in neural network architectures to articulate the theory, and demonstrate its ability to explain a wide range of phenomena associated with control-dependent behavior. Furthermore, we argue that the need for control, arising from the shared use of the same resources by different tasks, reflects the optimization of a fundamental tradeoff intrinsic to network architectures:  the increase in learning efficacy associated with the use of shared representations, versus the efficiency of parallel processing (i.e., multitasking) associated with task-dedicated representations.  The theory helps frame a formally rigorous, normative approach to the tradeoff between control-dependent processing versus automaticity, and relates to a number of other fundamental principles and phenomena concerning cognitive function, and computation more generally.},
	urldate = {2021-12-10},
	institution = {PsyArXiv},
	author = {Musslick, S. and Saxe, A. and Hoskin, A.N. and Reichman, D. and Cohen, J.D.},
	year = {2020},
	doi = {10.31234/osf.io/jkhdf},
	note = {type: article},
	keywords = {publications},
	file = {Full Text PDF:/Users/asaxe/Zotero/storage/3GRSXL6J/Musslick et al. - 2020 - On the Rational Boundedness of Cognitive Control .pdf:application/pdf},
}

@inproceedings{cao_characterizing_2020,
	title = {Characterizing emergent representations in a space of candidate learning rules for deep networks},
	url = {https://proceedings.neurips.cc/paper/1995/file/feab05aa91085b7a8012516bc3533958-Paper.pdf},
	urldate = {2021-03-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 33},
	author = {Cao, Y. and Summerfield, C. and Saxe, A.},
	year = {2020},
	keywords = {publications},
	file = {NIPS Full Text PDF:/Users/asaxe/Zotero/storage/G54X3WYW/Barto and Houk - 1996 - A Predictive Switching Model of Cerebellar Movemen.pdf:application/pdf;NIPS Snapshot:/Users/asaxe/Zotero/storage/CQ5C7IMR/6275d7071d005260ab9d0766d6df1145-Paper.html:text/html},
}


@inproceedings{Masis2020,
abstract = {Balancing the speed and accuracy of decisions is crucial for survival, but how organisms manage this trade-off during learning is largely unknown. Here, we track this trade-off during perceptual learning in rats and simulated agents. At the start of learning, rats chose long reaction times that did not optimize instantaneous reward rate, but by the end of learning chose near-optimal reaction times. To understand this behavior, we analyzed learning dynamics in a recurrent neural network model of the task. The model reveals a fundamental trade-off between instantaneous reward rate and perceptual learning speed, putting the goals of learning quickly and accruing immediate reward in tension. We find that the rats’ strategy of long initial responses can dramatically expedite learning, yielding higher total reward over task engagement. Our results demonstrate that prioritizing learning can be advantageous from a total reward perspective, and suggest that rats engage in cognitive control of learning.},
author = {Masis, J.A. and Chapman, T. and Rhee, J.Y. and Cox, D.D. and Saxe, A.M.},
booktitle = {bioRxiv},
file = {:Users/asaxe/Dropbox/Papers/2020.09.01.259911v1.full.pdf:pdf},
keywords = {arxiv},
pages = {1--48},
title = {{Rats strategically manage learning during perceptual decision making}},
year = {2020}
}

@inproceedings{Saxe2020,
abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence (AI) research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This perspective has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterise computations or neural codes, or who wish to understand perception, attention, memory, and executive functions? In this Perspective, our goal is to offer a roadmap for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics, and neural representation in artificial and biological systems. We highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
archivePrefix = {arXiv},
arxivId = {2004.07580},
author = {Saxe, A. and Nelli, S. and Summerfield, C.},
booktitle = {arXiv},
eprint = {2004.07580},
file = {:Users/asaxe/Dropbox/Papers/2004.07580.pdf:pdf},
keywords = {arxiv},
title = {{If deep learning is the answer, then what is the question?}},
url = {http://arxiv.org/abs/2004.07580},
year = {2020}
}

@article{Richards2019,
abstract = {Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.},
author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, Jo{\~{a}}o and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
doi = {10.1038/s41593-019-0520-2},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {publications},
month = {nov},
number = {11},
pages = {1761--1770},
title = {{A deep learning framework for neuroscience}},
url = {http://www.nature.com/articles/s41593-019-0520-2},
volume = {22},
year = {2019}
}
@inproceedings{Goldt2019a,
abstract = {Deep neural networks achieve stellar generalisation even when they have enough parameters to easily fit all their training data. We study this phenomenon by analysing the dynamics and the performance of over-parameterised two-layer neural networks in the teacher-student setup, where one network, the student, is trained on data generated by another network, called the teacher. We show how the dynamics of stochastic gradient descent (SGD) is captured by a set of differential equations and prove that this description is asymptotically exact in the limit of large inputs. Using this framework, we calculate the final generalisation error of student networks that have more parameters than their teachers. We find that the final generalisation error of the student increases with network size when training only the first layer, but stays constant or even decreases with size when training both layers. We show that these different behaviours have their root in the different solutions SGD finds for different activation functions. Our results indicate that achieving good generalisation in neural networks goes beyond the properties of SGD alone and depends on the interplay of at least the algorithm, the model architecture, and the data set.},
archivePrefix = {arXiv},
arxivId = {1906.08632},
author = {Goldt, Sebastian and Advani, Madhu S. and Saxe, Andrew M. and Krzakala, Florent and Zdeborov{\'{a}}, Lenka},
booktitle = {NeurIPS},
eprint = {1906.08632},
file = {:Users/asaxe/Dropbox/Papers/1906.08632(1).pdf:pdf},
keywords = {publications},
month = {jun},
title = {{Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup}},
year = {2019}
}
@article{Saxe2019,
abstract = {An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: What are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep-learning dynamics to give rise to these regularities.},
archivePrefix = {arXiv},
arxivId = {1810.10531},
author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
doi = {10.1073/pnas.1820226116},
eprint = {1810.10531},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2019 - A mathematical theory of semantic development in deep neural networks.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {publications},
number = {23},
pages = {11537--11546},
title = {{A mathematical theory of semantic development in deep neural networks}},
url = {http://arxiv.org/abs/1810.10531 http://www.pnas.org/lookup/doi/10.1073/pnas.1820226116},
volume = {116},
year = {2019}
}
@article{Saxe2019a,
abstract = {The practical successes of deep neural networks have not been matched by theoretical progress that satisfyingly explains their behavior. In this work, we study the information bottleneck (IB) theory of deep learning, which makes three specific claims: first, that deep networks undergo two distinct phases consisting of an initial fitting phase and a subsequent compression phase; second, that the compression phase is causally related to the excellent generalization performance of deep networks; and third, that the compression phase occurs due to the diffusion-like behavior of stochastic gradient descent. Here we show that none of these claims hold true in the general case. Through a combination of analytical results and simulation, we demonstrate that the information plane trajectory is predominantly a function of the neural nonlinearity employed: double-sided saturating nonlinearities like tanh yield a compression phase as neural activations enter the saturation regime, but linear activation functions and single-sided saturating nonlinearities like the widely used ReLU in fact do not. Moreover, we find that there is no evident causal connection between compression and generalization: networks that do not compress are still capable of generalization, and vice versa. Next, we show that the compression phase, when it exists, does not arise from stochasticity in training by demonstrating that we can replicate the IB findings using full batch gradient descent rather than stochastic gradient descent. Finally, we show that when an input domain consists of a subset of task-relevant and task-irrelevant information, hidden representations do compress the task-irrelevant information, although the overall information about the input may monotonically increase with training time, and that this compression happens concurrently with the fitting process rather than during a subsequent compression period.},
author = {Saxe, A.M. and Bansal, Y. and Dapello, J. and Advani, M. and Kolchinsky, A. and Tracey, B.D. and Cox, D.D.},
doi = {10.1088/1742-5468/ab3985},
file = {:Users/asaxe/Dropbox/Papers/Saxe{\_}2019{\_}J.{\_}Stat.{\_}Mech.{\_}2019{\_}124020(1).pdf:pdf},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {publications},
month = {dec},
number = {12},
pages = {124020},
publisher = {IOP Publishing},
title = {{On the information bottleneck theory of deep learning}},
url = {https://iopscience.iop.org/article/10.1088/1742-5468/ab3985},
volume = {2019},
year = {2019}
}

@inproceedings{Goldt2019,
abstract = {Deep neural networks achieve stellar generalisation on a variety of problems, despite often being large enough to easily fit all their training data. Here we study the generalisation dynamics of two-layer neural networks in a teacher-student setup, where one network, the student, is trained using stochastic gradient descent (SGD) on data generated by another network, called the teacher. We show how for this problem, the dynamics of SGD are captured by a set of differential equations. In particular, we demonstrate analytically that the generalisation error of the student increases linearly with the network size, with other relevant parameters held constant. Our results indicate that achieving good generalisation in neural networks depends on the interplay of at least the algorithm, its learning rate, the model architecture, and the data set.},
archivePrefix = {arXiv},
arxivId = {1901.09085},
author = {Goldt, S. and Advani, M.S. and Saxe, A.M. and Krzakala, F. and Zdeborov{\'{a}}, L.},
booktitle = {ICML Workshop on Theoretical Physics for Deep Learning Theory},
eprint = {1901.09085},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Goldt et al. - 2019 - Generalisation dynamics of online learning in over-parameterised neural networks.pdf:pdf},
keywords = {arxiv},
title = {{Generalisation dynamics of online learning in over-parameterised neural networks}},
url = {http://arxiv.org/abs/1901.09085},
year = {2019}
}
@article{Zhang2018,
abstract = {Finding parameters that minimise a loss function is at the core of many machine learning methods. The Stochastic Gradient Descent algorithm is widely used and delivers state of the art results for many problems. Nonetheless, Stochastic Gradient Descent typically cannot find the global minimum, thus its empirical effectiveness is hitherto mysterious. We derive a correspondence between parameter inference and free energy minimisation in statistical physics. The degree of undersampling plays the role of temperature. Analogous to the energy-entropy competition in statistical physics, wide but shallow minima can be optimal if the system is undersampled, as is typical in many applications. Moreover, we show that the stochasticity in the algorithm has a non-trivial correlation structure which systematically biases it towards wide minima. We illustrate our argument with two prototypical models: image classification using deep learning, and a linear neural network where we can analytically reveal the relationship between entropy and out-of-sample error.},
archivePrefix = {arXiv},
arxivId = {1803.01927},
author = {Zhang, Y. and Saxe, A.M. and Advani, M.S. and Lee, A.A.},
doi = {10.1080/00268976.2018.1483535},
eprint = {1803.01927},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2018 - Energy-entropy competition and the effectiveness of stochastic gradient descent in machine learning.pdf:pdf},
journal = {Molecular Physics},
keywords = {publications},
pages = {1--10},
title = {{Energy-entropy competition and the effectiveness of stochastic gradient descent in machine learning}},
year = {2018}
}
@inproceedings{Nye2018,
abstract = {Many theories of deep learning have shown that a deep network can require dra- matically fewer resources to represent a given function compared to a shallow network. But a question remains: can these efficient representations be learned using current deep learning techniques? In this work, we test whether standard deep learning methods can in fact find the efficient representations posited by sev- eral theories of deep representation. Specifically, we train deep neural networks to learn two simple functions with known efficient solutions: the parity function and the fast Fourier transform. We find that using gradient-based optimization, a deep network does not learn the parity function, unless initialized very close to a hand-coded exact solution. We also find that a deep linear neural network does not learn the fast Fourier transform, even in the best-case scenario of infinite training data, unless the weights are initialized very close to the exact hand-coded solution. Our results suggest that not every element of the class of compositional functions can be learned efficiently by a deep network, and further restrictions are necessary to understand what functions are both efficiently representable and learnable.},
address = {Vancouver, Canada},
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06434v1},
author = {Nye, M. and Saxe, A.},
booktitle = {Workshop Track at the International Conference on Learning Representations},
doi = {10.1051/0004-6361/201527329},
editor = {Bengio, Y. and LeCun, Y.},
eprint = {arXiv:1511.06434v1},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Nye, Saxe - 2018 - Are Efficient Deep Representations Learnable.pdf:pdf},
isbn = {2004012439},
issn = {0004-6361},
keywords = {publications},
pmid = {23459267},
title = {{Are Efficient Deep Representations Learnable?}},
year = {2018}
}
@inproceedings{Saxe2018,
address = {Vancouver, Canada},
author = {Saxe, A.M. and Bansal, Y. and Dapello, J. and Advani, M. and Kolchinsky, A. and Tracey, B.D. and Cox, D.D.},
booktitle = {International Conference on Learning Representations},
editor = {Bengio, Y. and LeCun, Y.},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2018 - On the Information Bottleneck Theory of Deep Learning.pdf:pdf},
isbn = {0444565191},
keywords = {publications},
title = {{On the Information Bottleneck Theory of Deep Learning}},
year = {2018}
}
@inproceedings{Bansal2018,
abstract = {In this work, we propose a new training method for finding minimum weight norm solutions in over-parameterized neural networks (NNs). This method seeks to improve training speed and generalization performance by framing NN training as a constrained optimization problem wherein the sum of the norm of the weights in each layer of the network is minimized, under the constraint of exactly fitting training data. It draws inspiration from support vector machines (SVMs), which are able to generalize well, despite often having an infinite number of free parameters in their primal form, and from recent theoretical generalization bounds on NNs which suggest that lower norm solutions generalize better. To solve this constrained optimization problem, our method employs Lagrange multipliers that act as integrators of error over training and identify `support vector'-like examples. The method can be implemented as a wrapper around gradient based methods and uses standard back-propagation of gradients from the NN for both regression and classification versions of the algorithm. We provide theoretical justifications for the effectiveness of this algorithm in comparison to early stopping and {\$}L{\_}2{\$}-regularization using simple, analytically tractable settings. In particular, we show faster convergence to the max-margin hyperplane in a shallow network (compared to vanilla gradient descent); faster convergence to the minimum-norm solution in a linear chain (compared to {\$}L{\_}2{\$}-regularization); and initialization-independent generalization performance in a deep linear network. Finally, using the MNIST dataset, we demonstrate that this algorithm can boost test accuracy and identify difficult examples in real-world datasets.},
archivePrefix = {arXiv},
arxivId = {1806.00730},
author = {Bansal, Y. and Advani, M. and Cox, D.D. and Saxe, A.M.},
booktitle = {arXiv},
eprint = {1806.00730},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Bansal et al. - 2018 - Minnorm training an algorithm for training over-parameterized deep neural networks.pdf:pdf},
keywords = {arxiv},
title = {{Minnorm training: an algorithm for training over-parameterized deep neural networks}},
year = {2018}
}
@inproceedings{Saxe*2018,
address = {Denver},
author = {Saxe*, A.M. and Advani*, M.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, Advani - 2018 - A theory of memory replay and generalization performance in neural networks.pdf:pdf},
keywords = {abstract},
organization = {*Equal contributions.},
title = {{A theory of memory replay and generalization performance in neural networks}},
year = {2018}
}
@inproceedings{Masis2018,
address = {Denver},
author = {Mas{\'{i}}s, J. and Saxe, A.M. and Cox, D.D.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Mas{\'{i}}s, Saxe, Cox - 2018 - Rats optimize reward rate {\&} learning speed in a 2-AFC task.pdf:pdf},
keywords = {abstract},
title = {{Rats optimize reward rate and learning speed in a 2-AFC task}},
year = {2018}
}
@inproceedings{Earle2018,
address = {Vancouver, Canada},
author = {Earle, A.C. and Saxe, A.M. and Rosman, B.},
booktitle = {International Conference on Learning Representations},
editor = {Bengio, Y. and LeCun, Y.},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Earle, Saxe, Rosman - 2018 - Hierarchical Subtask Discovery with Non-Negative Matrix Factorization.pdf:pdf},
keywords = {publications},
title = {{Hierarchical Subtask Discovery with Non-Negative Matrix Factorization}},
year = {2018}
}
@inproceedings{Advani2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.03667v1},
author = {Advani*, M. and Saxe*, A.M.},
booktitle = {arXiv},
eprint = {arXiv:1710.03667v1},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Advani, Saxe - 2017 - High-dimensional dynamics of generalization error in neural networks.pdf:pdf},
keywords = {arxiv},
organization = {*Equal contributions.},
title = {{High-dimensional dynamics of generalization error in neural networks}},
year = {2017}
}
@inproceedings{Musslick2017,
author = {Musslick, S. and Saxe, A.M. and Ozcimder, K. and Dey, B. and Henselman, G. and Cohen, J.D.},
booktitle = {Annual meeting of the Cognitive Science Society},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Musslick et al. - 2017 - Multitasking Capability Versus Learning Efficiency in Neural Network Architectures.pdf:pdf},
keywords = {publications},
pages = {829--834},
title = {{Multitasking Capability Versus Learning Efficiency in Neural Network Architectures}},
year = {2017}
}
@inproceedings{Saxe2017,
address = {Sydney, Australia},
author = {Saxe, A.M. and Earle, A.C. and Rosman, B.},
booktitle = {International Conference on Machine Learning},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, Earle, Rosman - 2017 - Hierarchy Through Composition with Multitask LMDPs.pdf:pdf;:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, Earle, Rosman - 2017 - Hierarchy Through Composition with Multitask LMDPs(2).pdf:pdf},
keywords = {publications},
title = {{Hierarchy Through Composition with Multitask LMDPs}},
year = {2017}
}
@article{Earle2017,
address = {Sydney, Australia},
archivePrefix = {arXiv},
arxivId = {arXiv:1708.00463v1},
author = {Earle, A.C. and Saxe, A.M. and Rosman, B.},
eprint = {arXiv:1708.00463v1},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Earle, Saxe, Rosman - 2017 - Hierarchical Subtask Discovery With Non-Negative Matrix Factorization.pdf:pdf},
journal = {Workshop on Lifelong Learning: A Reinforcement Learning Approach at ICML},
keywords = {publications},
title = {{Hierarchical Subtask Discovery With Non-Negative Matrix Factorization}},
year = {2017}
}
@inproceedings{Baldassano*2016,
address = {Salt Lake City},
author = {Baldassano*, C. and Saxe*, A.M.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Baldassano, Saxe - 2016 - A theory of learning dynamics in perceptual decision-making.pdf:pdf},
keywords = {abstract},
organization = {*Equal contributions.},
title = {{A theory of learning dynamics in perceptual decision-making}},
year = {2016}
}
@inproceedings{Saxe2016,
address = {Salt Lake City},
author = {Saxe, A.M. and Norman, K.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, Norman - 2016 - Optimal storage capacity associative memories exhibit retrieval-induced forgetting.pdf:pdf},
keywords = {abstract},
title = {{Optimal storage capacity associative memories exhibit retrieval-induced forgetting}},
year = {2016}
}
@inproceedings{Tsai2016,
abstract = {We present a novel neural network algorithm, the Tensor Switching (TS) network, which generalizes the Rectified Linear Unit (ReLU) nonlinearity to tensor-valued hidden units. The TS network copies its entire input vector to different locations in an expanded representation, with the location determined by its hidden unit activity. In this way, even a simple linear readout from the TS representation can implement a highly expressive deep-network-like function. The TS network hence avoids the vanishing gradient problem by construction, at the cost of larger representation size. We develop several methods to train the TS network, including equivalent kernels for infinitely wide and deep TS networks, a one-pass linear learning algorithm, and two backpropagation-inspired representation learning algorithms. Our experimental results demonstrate that the TS network is indeed more expressive and consistently learns faster than standard ReLU networks.},
archivePrefix = {arXiv},
arxivId = {1610.10087},
author = {Tsai*, C.Y. and Saxe*, A. and Cox, D.},
booktitle = {Advances in Neural Information Processing Systems 29},
eprint = {1610.10087},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Tsai, Saxe, Cox - 2016 - Tensor Switching Networks.pdf:pdf;:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Tsai, Saxe, Cox - 2016 - Tensor Switching Networks(2).pdf:pdf},
issn = {10495258},
keywords = {publications},
organization = {*Equal contributions.},
title = {{Tensor Switching Networks}},
year = {2016}
}
@article{Mcclelland2016,
author = {McClelland, J.L. and Sadeghi, Z. and Saxe, A.M.},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/McClelland, Sadeghi, Saxe - 2016 - A Critique of Pure Hierarchy Uncovering Cross-Cutting Structure in a Natural Dataset.pdf:pdf},
journal = {Neurocomputational Models of Cognitive Development and Processing},
keywords = {publications},
pages = {51--68},
publisher = {World Scientific},
title = {{A Critique of Pure Hierarchy: Uncovering Cross-Cutting Structure in a Natural Dataset}},
year = {2016}
}
@inproceedings{Saxe2016a,
address = {Philadelphia},
author = {Saxe, A.M.},
booktitle = {Annual meeting of the Cognitive Science Society},
file = {:Users/asaxe/Desktop/From Old Pro/postdoctoralwork/website/papers/Saxe - 2016 - Inferring actions, intentions, and causal relations in a neural network.pdf:pdf},
keywords = {other},
title = {{Inferring actions, intentions, and causal relations in a neural network}},
year = {2016}
}
@inproceedings{Saxe2015,
address = {Salt Lake City},
author = {Saxe, A.M.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe - 2015 - A deep learning theory of perceptual learning dynamics.pdf:pdf},
keywords = {abstract},
title = {{A deep learning theory of perceptual learning dynamics}},
year = {2015}
}
@inproceedings{Goodfellow2015,
address = {San Diego, CA},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6544v4},
author = {Goodfellow, I.J. and Vinyals, O. and Saxe, A.M.},
booktitle = {International Conference on Learning Representations},
eprint = {arXiv:1412.6544v4},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow, Vinyals, Saxe - 2015 - Qualitatively Characterizing Neural Network Optimization Problems(2).pdf:pdf},
keywords = {publications},
organization = {Oral presentation.},
title = {{Qualitatively Characterizing Neural Network Optimization Problems}},
year = {2015}
}
@inproceedings{Lee2015,
address = {Salt Lake City},
author = {Lee, R. and Saxe, A.M.},
booktitle = {Computational and Systems Neuroscience Conference},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Saxe - 2015 - The Effect of Pooling in a Deep Learning Model of Perceptual Learning.pdf:pdf},
keywords = {abstract},
title = {{The Effect of Pooling in a Deep Learning Model of Perceptual Learning}},
year = {2015}
}
@inproceedings{Saxe2014a,
address = {Quebec City},
author = {Saxe, A.M.},
booktitle = {Annual meeting of the Cognitive Science Society},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe - 2014 - Multitask Model-free Reinforcement Learning(2).pdf:pdf},
keywords = {other},
title = {{Multitask Model-free Reinforcement Learning}},
year = {2014}
}
@misc{Lee2014,
address = {Quebec City},
author = {Lee, R. and Saxe, A.M. and McClelland, J.},
booktitle = {Annual meeting of the Cognitive Science Society},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Saxe, McClelland - 2014 - Modeling Perceptual Learning with Deep Networks.pdf:pdf},
keywords = {other},
title = {{Modeling Perceptual Learning with Deep Networks}},
year = {2014}
}
@inproceedings{Saxe2014,
abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
address = {Banff, Canada},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6120v3},
author = {Saxe, A.M. and McClelland, J.L. and Ganguli, S.},
booktitle = {International Conference on Learning Representations},
editor = {Bengio, Y. and LeCun, Y.},
eprint = {arXiv:1312.6120v3},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2014 - Exact solutions to the nonlinear dynamics of learning in deep linear neural networks(2).pdf:pdf},
keywords = {publications},
organization = {Oral presentation.},
title = {{Exact solutions to the nonlinear dynamics of learning in deep linear neural networks}},
year = {2014}
}
@inproceedings{Saxe2013,
abstract = {Psychological experiments have revealed remarkable regularities in the developmental time course of cognition. Infants gen- erally acquire broad categorical distinctions (i.e., plant/animal) before finer ones (i.e., bird/fish), and periods of little change are often punctuated by stage-like transitions. This pattern of progressive differentiation has also been seen in neural network models as they learn from exposure to training data. Our work explains why the networks exhibit these phenomena. We find solutions to the dynamics of error-correcting learning in linear three layer neural networks. These solutions link the statistics of the training set and the dynamics of learning in the network, and characterize formally how learning leads to the emergence of structured representations for arbitrary training environments. We then consider training a neural network on data generated by a hierarchically structured probabilistic gen- erative process. Our results reveal that, for a broad class of such structures, the learning dynamics must exhibit progressive, coarse-to-fine differentiation with stage-like transitions punctuating longer dormant periods.},
address = {Austin, TX},
author = {Saxe, A.M. and McClelland, J.L. and Ganguli, S.},
booktitle = {Annual meeting of the Cognitive Science Society},
editor = {Knauff, M. and Paulen, M. and Sebanz, N. and Wachsmuth, I.},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2013 - Learning hierarchical category structure in deep neural networks(2).pdf:pdf},
keywords = {publications},
organization = {Oral presentation},
pages = {1271--1276},
publisher = {Cognitive Science Society},
title = {{Learning hierarchical category structure in deep neural networks}},
year = {2013}
}
@inproceedings{Saxe2013a,
author = {Saxe, A.M. and McClelland, J.L. and Ganguli, S.},
booktitle = {NIPS Workshop on Deep Learning},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2013 - Dynamics of learning in deep linear neural networks.pdf:pdf;:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2013 - Dynamics of learning in deep linear neural networks(2).pdf:pdf},
keywords = {publications},
title = {{Dynamics of learning in deep linear neural networks}},
year = {2013}
}
@inproceedings{Saxe2013b,
address = {Salt Lake City},
author = {Saxe, A.M. and McClelland, J.L. and Ganguli, S.},
booktitle = {Computational and Systems Neuroscience Conference (COSYNE)},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe, McClelland, Ganguli - 2013 - A Mathematical Theory of Semantic Development.pdf:pdf},
keywords = {abstract},
title = {{A Mathematical Theory of Semantic Development}},
year = {2013}
}
@inproceedings{Saxe2011b,
author = {Saxe, A.M. and Bhand, M. and Mudur, R. and Suresh, B. and Ng, A.Y.},
booktitle = {Computational and Systems Neuroscience Conference (COSYNE)},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2011 - Modeling Cortical Representational Plasticity With Unsupervised Feature Learning.pdf:pdf},
keywords = {abstract},
title = {{Modeling Cortical Representational Plasticity With Unsupervised Feature Learning}},
year = {2011}
}
@article{Balci2010,
author = {Balci, F. and Simen, P. and Niyogi, R. and Saxe, A. and Hughes, J.A. and Holmes, P. and Cohen, J.D.},
doi = {10.3758/s13414-010-0049-7},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Balci et al. - 2011 - Acquisition of decision making criteria reward rate ultimately beats accuracy.pdf:pdf},
issn = {1943-3921},
journal = {Attention, Perception, {\&} Psychophysics},
keywords = {publications},
number = {2},
pages = {640--57},
publisher = {Springer},
title = {{Acquisition of decision making criteria: reward rate ultimately beats accuracy}},
url = {http://www.springerlink.com/index/T3W97L53501515P8.pdf},
volume = {73},
year = {2011}
}
@inproceedings{Saxe2011,
abstract = {The efficient coding hypothesis holds that neural receptive fields are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism's life- time, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive field properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive field properties in response to experimentally altered environ- mental statistics. Based on these modeling results we propose these models as phenomenological models of receptive field plasticity during an organism's life- time. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, first proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices.},
author = {Saxe, A. and Bhand, M. and Mudur, R. and Suresh, B. and Ng, A.Y.},
booktitle = {Advances in Neural Information Processing Systems 25},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2011 - Unsupervised learning models of primary cortical receptive fields and receptive field plasticity.pdf:pdf;:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - Unknown - Supplementary Material Unsupervised learning models of primary cortical receptive fields and receptive field pl.pdf:pdf},
keywords = {publications},
title = {{Unsupervised learning models of primary cortical receptive fields and receptive field plasticity}},
year = {2011}
}
@inproceedings{Saxe2011a,
abstract = {Recently two anomalous results in the literature have shown that certain feature learning architectures can yield useful features for object recognition tasks even with untrained, random weights. In this paper we pose the question: why do random weights sometimes do so well? Our answer is that certain convolutional pooling architectures can be inherently frequency selective and translation invariant, even with random weights. Based on this we demonstrate the viability of extremely fast architecture search by using random weights to evaluate candidate architectures, thereby sidestepping the time-consuming learning process. We then show that a surprising fraction of the performance of certain state-of-the-art methods can be attributed to the architecture alone.},
author = {Saxe, A.M. and Koh, P.W. and Chen, Z. and Bhand, M. and Suresh, B. and Ng, A.Y.},
booktitle = {Proceedings of the 28th International Conference on Machine Learning},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2011 - On Random Weights and Unsupervised Feature Learning.pdf:pdf},
keywords = {publications},
title = {{On Random Weights and Unsupervised Feature Learning}},
year = {2011}
}
@inproceedings{Saxe2010,
author = {Saxe, A.M. and Koh, P.W. and Chen, Z. and Bhand, M. and Suresh, B. and Ng, A.Y.},
booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2010 - On Random Weights and Unsupervised Feature Learning.pdf:pdf;:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Saxe et al. - 2010 - On Random Weights and Unsupervised Feature Learning(2).pdf:pdf},
keywords = {publications},
title = {{On Random Weights and Unsupervised Feature Learning}},
year = {2010}
}
@inproceedings{Baldassano2009,
author = {Baldassano, C.A. and Franken, G.H. and Mayer, J.R. and Saxe, A.M. and Yu, D.D.},
booktitle = {Proceedings of SPIE},
doi = {10.1117/12.810509},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Baldassano et al. - 2009 - Kratos Princeton University's entry in the 2008 Intelligent Ground Vehicle Competition.pdf:pdf},
keywords = {publications},
title = {{Kratos: Princeton University's entry in the 2008 Intelligent Ground Vehicle Competition}},
url = {http://link.aip.org/link/PSISDG/v7252/i1/p72520I/s1{\&}Agg=doi},
year = {2009}
}
@inproceedings{Goodfellow2009,
author = {Goodfellow, I.J. and Le, Q.V. and Saxe, A.M. and Lee, H. and Ng, A.Y.},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {Bengio, Y. and Schuurmans, D.},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow et al. - 2009 - Measuring Invariances in Deep Networks.pdf:pdf},
keywords = {publications},
title = {{Measuring Invariances in Deep Networks}},
year = {2009}
}
@article{Atreya2006,
author = {Atreya, A.R. and Cattle, B.C. and Collins, B.M. and Essenburg, B. and Franken, G.H. and Saxe, A.M. and Schiffres, S.N. and Kornhauser, A.L.},
doi = {10.1002/rob.20141},
file = {:Users/asaxe/Library/Application Support/Mendeley Desktop/Downloaded/Atreya et al. - 2006 - Prospect Eleven Princeton University's entry in the 2005 DARPA Grand Challenge.pdf:pdf},
issn = {15564959},
journal = {Journal of Field Robotics},
keywords = {publications},
number = {9},
pages = {745--753},
publisher = {万方数据资源系统},
title = {{Prospect Eleven: Princeton University's entry in the 2005 DARPA Grand Challenge}},
url = {http://doi.wiley.com/10.1002/rob.20141},
volume = {23},
year = {2006}
}
